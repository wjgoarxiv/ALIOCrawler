#!/usr/bin/env python

# Import libraries
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import re
import time
import datetime
import os
import sys
import json
import matplotlib.pyplot as plt
import seaborn as sns
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException
import chromedriver_autoinstaller
from selenium.common.exceptions import NoSuchElementException
import argparse
from pyfiglet import Figlet

def main():
    f = Figlet(font='big')
    print(f.renderText('ALIOCrawler'))
    print('------------------------')
    print('\n')
    print('If you have any questions, please send your questions to my email.')
    print('\nOr, please suggest errors and areas that need updating.')
    print('\n ğŸ“¨ woo_go@yahoo.com')
    print('\n')
    print('\nVisit https://github.com/wjgoarxiv/ALIOCrawler for more information.')
    print('\n')
    print('------------------------')
    print('\n')

    # Setting driver options.
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    # Start argument parser
    parser = argparse.ArgumentParser()

    # Add arguments
    parser.add_argument('-s', '--search', type=str, help='ê²€ìƒ‰í•˜ê³ ì í•˜ëŠ” ê³µê³ ê¸°ê´€ì˜ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆì‹œ: ìš¸ì‚°ê³¼í•™ê¸°ìˆ ì›).', default='ìš¸ì‚°ê³¼í•™ê¸°ìˆ ì›')
    parser.add_argument('-o', '--output', type=str, help='ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì €ì¥í•  íŒŒì¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆì‹œ: ALIO_output). Output íŒŒì¼ì€ CSV íŒŒì¼ í˜•íƒœë¡œ ì €ì¥ë©ë‹ˆë‹¤.', default = 'ALIO_output')

    args = parser.parse_args()

    # Assign arguments to variables
    search = args.search # ë¬´ì—‡ì„ ê²€ìƒ‰í•  ê²ƒì¸ê°€
    output_file = args.output # íŒŒì¼ ì•„ì›ƒí’‹ ì´ë¦„ì€ ë¬´ì—‡ìœ¼ë¡œ í•  ê²ƒì¸ê°€? 

    # Automatically install the matching chromedriver version
    chromedriver_autoinstaller.install()

    # Create a new instance of the Chrome driver
    driver = webdriver.Chrome('chromedriver', options=options)

    # Go to the ALIO website 
    driver.get("https://www.alio.go.kr/main.do")

    # ê²€ìƒ‰ë€ì˜ XPathëŠ” "//*[@id="content"]/div[1]/div/div/div[1]/div/input" ì…ë‹ˆë‹¤.
    driver.find_element(By.XPATH, "//*[@id='content']/div[1]/div/div/div[1]/div/input").send_keys(search)
    driver.find_element(By.XPATH, "//*[@id='content']/div[1]/div/div/div[1]/div/input").send_keys(Keys.ENTER)

    # implicit wait 4 sec
    driver.implicitly_wait(4)
    time.sleep(1.5)

    # "//*[@id="content"]/div/div[3]/div/div/button[6]" ë²„íŠ¼ì„ ëˆŒëŸ¬ "ì±„ìš©ì •ë³´" íƒ­ìœ¼ë¡œ ì§„ì…í•©ë‹ˆë‹¤. 
    driver.find_element(By.XPATH, "//*[@id='content']/div/div[3]/div/div/button[6]").click() 

    driver.implicitly_wait(4)
    time.sleep(1.5)

    print("INFO ì…ë ¥í•˜ì‹  ê²€ìƒ‰ì–´ëŠ” '{}' ì…ë‹ˆë‹¤.".format(search))
    print("INFO output íŒŒì¼ ì´ë¦„ì€ '{}' ì…ë‹ˆë‹¤.".format(output_file))
    print("INFO í˜¹ì‹œ ì›í•˜ëŠ” ì¸í’‹ ê°’ì´ ì•„ë‹Œê°€ìš”? `$ aliocrawler -h` ë¥¼ ì…ë ¥í•´ ì¸í’‹ ê°’ì„ ë³€ê²½í•´ë³´ì„¸ìš”!")
    time.sleep(1.2) 

    # Page number identification
    page_num = 1
    while True:
        try:
            driver.find_element(By.XPATH, "//*[@id='content']/div/div[4]/div/dl/dd/div/div[2]/ul/li[{}]/a".format(page_num))
            page_num += 1
        except NoSuchElementException:
            break

    print("INFO ì´ í˜ì´ì§€ ìˆ˜ëŠ” {}ê°œê°€ ìˆë„¤ìš”. ì´ì œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤!".format(page_num-1))

    # í˜ì´ì§€ ë³„ë¡œ ë£¨í”„ë¥¼ ì§„í–‰í•˜ë˜, í˜ì´ì§€ê°€ ì—†ë‹¤ë©´ NoSuchElementExceptionì„ ë°œìƒì‹œí‚µë‹ˆë‹¤.
    for i in range(1, page_num):
      time.sleep (1)

      try:
        driver.find_element(By.XPATH, "//*[@id='content']/div/div[4]/div/dl/dd/div/div[2]/ul/li[{}]/a".format(i)).click()
      except NoSuchElementException as e:
        pass

      recruit_name = []
      recruit_date = []
      recruit_link = []

      time.sleep(1)

      #í•œ í˜ì´ì§€ ë‚´ì— ìˆëŠ” ê³µê³ ì˜ ìˆ˜ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
      recruit_num = 1
      while True:
        try:
          driver.find_element(By.XPATH, "//*[@id='content']/div/div[4]/div/dl/dd/div/div[1]/div/ul/li[{}]".format(recruit_num))
          recruit_num += 1
        except NoSuchElementException:
          break

      print("INFO í˜„ì¬ í˜ì´ì§€ì—ëŠ” {}ê°œì˜ ê³µê³ ê°€ ìˆìŠµë‹ˆë‹¤. ê³µê³  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°ì—ëŠ” ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.".format(recruit_num-1))
      # í•œ í˜ì´ì§€ ë‚´ì— ìˆëŠ” ê³µê³ ì˜ ìˆ˜ë§Œí¼ ë°˜ë³µë¬¸ì„ ëŒë¦½ë‹ˆë‹¤.
      try:
        for i in range(1, recruit_num):
          recruit_name.append(driver.find_element(By.XPATH, "//*[@id='content']/div/div[4]/div/dl/dd/div/div[1]/div/ul/li[{}]/p[1]/span[3]/a".format(i)).text)
      except NoSuchElementException:
        pass

      try:
        for i in range(1, recruit_num):
          recruit_date.append(driver.find_element(By.XPATH, "//*[@id='content']/div/div[4]/div/dl/dd/div/div[1]/div/ul/li[{}]/p[2]/span[2]".format(i)).text)
      except NoSuchElementException:
        pass

      try:
        for i in range(1, recruit_num):
          # ê³µê³  ì •ë³´ íŒì—…ì°½ì„ ë„ìš°ê¸° ìœ„í•´ "//*[@id="content"]/div/div[4]/div/dl/dd/div/div[1]/div/ul/li[1]/p[1]/span[3]/a" ë²„íŠ¼ì„ ëˆ„ë¦…ë‹ˆë‹¤.
          driver.find_element(By.XPATH, "//*[@id='content']/div/div[4]/div/dl/dd/div/div[1]/div/ul/li[{}]/p[1]/span[3]/a".format(i)).send_keys(Keys.ENTER)
          # ìƒˆë¡œ íŒì—…ëœ ì°½ì„ ë‹«ìŠµë‹ˆë‹¤. ê¸°ì¡´ ì°½ì´ ë‹«íˆì§€ ì•Šë„ë¡ ì£¼ì˜í•©ë‹ˆë‹¤. 
          driver.switch_to.window(driver.window_handles[1])
          # íŒì—…ì°½ì˜ URLì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
          recruit_link.append(driver.current_url)
          driver.close()
          driver.switch_to.window(driver.window_handles[0])

          # í”„ë¡œê·¸ë ˆìŠ¤ ë°”ë¥¼ ìœ„í•œ printë¬¸ì…ë‹ˆë‹¤. ì¶œë ¥ ì‹œ "1/20"ê³¼ ê°™ì´ ì¶œë ¥ë©ë‹ˆë‹¤.
          print("INFO í˜„ì¬ ì²˜ë¦¬ ì§„í–‰ì¤‘ì¸ í•­ëª© ë²ˆí˜¸:", i, "/", recruit_num-1, end='\r')

      except NoSuchElementException:
        pass 
      
      # ë£¨í”„ë¥¼ ëŒ ë•Œë§ˆë‹¤ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤. ë‚´ìš©ì´ ê³„ì†í•´ì„œ ì¶”ê°€ë  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. í—¤ë”ëŠ” í•œ ë²ˆë§Œ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
      df = pd.DataFrame({"ê³µê³ ëª…":recruit_name, "ê³µê³ ì¼":recruit_date, "ê³µê³ ë§í¬":recruit_link})
      # Use output_file as the file name of the output file ('csv')
      df.to_csv(output_file+'.csv', mode='a', encoding='utf-8-sig', index=False, header=False)
      print("INFO í˜„ì¬ í˜ì´ì§€ì˜ í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    print("INFO ëª¨ë“  í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ")
    print("INFO í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥ëœ CSV íŒŒì¼ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    # driver quit
    driver.quit()
    time.sleep(1)

# entry point
if __name__ == "__main__":
  main()